{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description:\n",
    "In this notebook we experiment with the log-loss function. We compare different methods to convert the cosine similarities to probabilities.\n",
    "\n",
    "# TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict, namedtuple\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from random import choice, sample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from src import PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding project_dir\n",
    "data_file = os.path.join(\n",
    "    PROJECT_ROOT, \"data\", \"processed\", \"newsapi_docs.csv\")\n",
    "model_dir = os.path.join(PROJECT_ROOT, \"outputs\", \"saved_models\")\n",
    "model_files = [os.path.join(model_dir, f) for f in os.listdir(\n",
    "    model_dir) if re.search(\"^doc2vec.*\\.model$\", f)]\n",
    "\n",
    "# Data structure for holding data for each document\n",
    "NewsDocument = namedtuple(\n",
    "    'NewsDocument', ['tags', 'id', 'col', 'category', 'words', 'split', 'original'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data into memory\n",
    "df = pd.read_csv(data_file, names=[\n",
    "                 'id', 'col', 'category', 'text', 'split', 'prep_text'])\n",
    "\n",
    "# Formatting data from DataFrame to Named Tuple for doc2vec training\n",
    "all_docs = [\n",
    "    NewsDocument([tag], row['id'], row['col'], row['category'], row['prep_text'].split(),\n",
    "                 row['split'], row['text']) for tag, (_, row) in enumerate(df.iterrows())\n",
    "    if row['prep_text'] is not None\n",
    "]\n",
    "train_docs = [doc for doc in all_docs if doc.split == 'train']\n",
    "test_docs = [doc for doc in all_docs if doc.split == 'test']\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading fitted models\n",
    "model_instance = models.doc2vec.Doc2Vec.load(model_files[0])\n",
    "\n",
    "# Creating objects to store data inside loop\n",
    "model_out = defaultdict(lambda: [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating constants (invariable across loop iterations)\n",
    "# sample train docs to evaluate inferred vs learned vectors\n",
    "train_samples = sample(train_docs, k=1000)\n",
    "test_doc_eval = choice(test_docs)  # random test doc to evaluate distances\n",
    "train_targets = [doc.category for doc in train_docs]\n",
    "test_targets = [doc.category for doc in test_docs]\n",
    "\n",
    "# Evaluating fitted model\n",
    "modelname = str(model_instance)\n",
    "\n",
    "# Get document vectors and targets\n",
    "train_vecs = [model_instance.docvecs[doc.tags[0]] for doc in train_docs]\n",
    "test_vecs = [model_instance.infer_vector(doc.words) for doc in test_docs]\n",
    "\n",
    "# Cosine similarity of test set instances\n",
    "sim_matrix = cosine_similarity(test_vecs)\n",
    "\n",
    "# Returns tuple with two arrays, each with the indices along one dimension\n",
    "tri_idx = np.triu_indices(len(test_targets), 1)\n",
    "\n",
    "# Pairs row and col indices and checks if corresponding observations have the same label\n",
    "y_labels = np.array([1 if test_targets[i] == test_targets[j] else 0 for i, j in zip(*tri_idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of cosine similarity values\n",
    "plt.hist(sim_matrix[tri_idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-loss of predicting whether pairs of observations belong to the same category\n",
    "k = 4\n",
    "# Convert cosine similarities to probability matrix using sigmoid function\n",
    "prob_matrix_sigmoid = 1/(1 + np.exp(-k*sim_matrix))\n",
    "# Get upper triangle of probability matrix to array\n",
    "y_pred_sigmoid = prob_matrix_sigmoid[tri_idx]  # the N(N−1)/2 independent predictions\n",
    "# Binary cross-entropy\n",
    "log_loss_sigmoid = y_labels * np.log(y_pred_sigmoid) + (1 - y_labels) * np.log(1 - y_pred_sigmoid)\n",
    "cost_sigmoid = -1 * np.mean(log_loss_sigmoid)\n",
    "\n",
    "print(\"Model %s log-loss: %f\\n\" % (modelname, cost_sigmoid ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution of the sigmoid probabilities\n",
    "plt.hist(y_pred_sigmoid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How the sigmoid probabilities change with different values of k\n",
    "fig, axes = plt.subplots(6, 2, figsize=(15,15))\n",
    "x = np.linspace(-10, 10, 50)\n",
    "for k, ax in enumerate(axes, start=1):\n",
    "    ax1, ax2 = ax\n",
    "    y = 1/(1 + np.exp(-k*x))\n",
    "    # Convert cosine similarities to probability matrix using sigmoid function\n",
    "    prob_matrix_sigmoid = 1/(1 + np.exp(-k*sim_matrix))\n",
    "    # Get upper triangle of probability matrix to array\n",
    "    y_pred_sigmoid = prob_matrix_sigmoid[tri_idx]  # the N(N−1)/2 independent predictions\n",
    "    ax1.hist(y_pred_sigmoid)\n",
    "    ax2.plot(x, y)\n",
    "    ax1.set_title(f\"Sigmoid with k={k}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above how the output probabilities varies according to k. Also how the sigmoid function looks for different k. One thing to notice is that for low values of k, our probabilities won't vary between 0 and 1 but on a smaller range because the sigmoid isn't steep enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique similarities (upper triangle) \n",
    "sim_unique = np.expand_dims(sim_matrix[tri_idx], axis=1)\n",
    "# Get probability array of unique upper triangle using MinMaxScaler [0.001, 0.999] to avoid 0 value \n",
    "y_pred_minmax = MinMaxScaler((0.001, 0.999)).fit_transform(sim_unique)[:, 0]\n",
    "# Binary cross-entropy\n",
    "log_loss_minmax = y_labels * np.log(y_pred_minmax) + (1 - y_labels) * np.log(1 - y_pred_minmax)\n",
    "cost_minmax = -1 * np.mean(log_loss_minmax)\n",
    "\n",
    "print(\"Model %s log-loss: %f\\n\" % (modelname, cost_minmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the MinMax probabilities\n",
    "plt.hist(y_pred_minmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the minmax scaling it seems that the probabilites are mainly concentrated on 0.5 which isn't something we are looking for.\n",
    "The distribution of the similarity scores are maintained. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
