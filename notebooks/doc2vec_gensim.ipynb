{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description:\n",
    "In this notebook we request 100 news articles from the NewsAPI (maximum allowed) and we use their truncated content to build a corpus, then we preprocess the corpus using the built CorpusPreprocess scikit-learn-like transformer. We train a gensim doc2vec model on the preprocessed corpus and we assess the model by checking document rankings for each document (the document should be the most similar with itself) and by comparing random documents' content with their similar documents' content. Finally, we request new documents from NewsAPI, apply preprocessing, infer their vectors and assess their quality by getting their most similar documents.\n",
    "\n",
    "# TODO:\n",
    "- add date, price, weekday, ... token to CorpusPreprocess\n",
    "- webscrape full content from urls provided by api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import CorpusPreprocess, check_random_doc_similarity, compare_documents, similarity_query\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import collections\n",
    "from newsapi import NewsApiClient\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import models\n",
    "# import numpy as np\n",
    "# from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "NEWSAPIKEY = os.environ.get(\"NEWSAPIKEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of article content:\n",
      "\n",
      "***Pregame Notes***\n",
      "- The Gators are seeking a sixth consecutive victory, and a fourth straight win in SEC play\n",
      "- Florida rose to No. 3 in the Associated Press Top 25 Poll, its highest ranking sinc… [+2342 chars]\n"
     ]
    }
   ],
   "source": [
    "# Init\n",
    "newsapi = NewsApiClient(api_key=NEWSAPIKEY)\n",
    "\n",
    "# Get news articles\n",
    "articles = newsapi.get_top_headlines(language='en',\n",
    "                                     category='sports',  # 'business','entertainment','general','health','science','sports','technology'\n",
    "                                      # domains='bbc.co.uk',\n",
    "                                      # from_param=datetime.today() - timedelta(30),\n",
    "                                      # to=datetime.today(),\n",
    "                                      page_size=100,\n",
    "                                      country='us')\n",
    "\n",
    "corpus = list(set([c['content'] for c in articles['articles'] if c['content']]))\n",
    "\n",
    "print(\"Example of article content:\\n\\n{}\".format(corpus[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/ test split\n",
    "test_idx = random.sample(range(len(corpus)), int(len(corpus) * 0.1))\n",
    "test_corpus = [corpus[i] for i in test_idx]\n",
    "train_corpus = list(set(corpus).difference(set(test_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of preprocessed article content:\n",
      "\n",
      "['pregam', 'note', 'gator', 'seek', 'sixth', 'consecut', 'victori', 'fourth', 'straight', 'win', 'sec', 'play', 'florida', 'rose', '3', 'associ', 'press', 'top', '25', 'poll', 'highest', 'rank', 'sinc', '2342', 'char']\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing - removing stopwords, lowercasing, strip accents, strip punctuation, stemming, max_df and min_df thresholds\n",
    "prep = CorpusPreprocess(stop_words=stopwords.words('english'), lowercase=True, strip_accents=True,\n",
    "                        strip_punctuation=punctuation, stemmer=True, max_df=0.2, min_df=2)\n",
    "processed_train_corpus = prep.fit_transform(train_corpus)\n",
    "processed_test_corpus = prep.transform(test_corpus)\n",
    "\n",
    "print(\"Example of preprocessed article content:\\n\\n{}\".format(processed_train_corpus[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TaggedDocument format (input to doc2vec)\n",
    "tagged_corpus = [models.doc2vec.TaggedDocument(text, [i]) for i, text in enumerate(processed_train_corpus)]\n",
    "\n",
    "# Doc2Vec model\n",
    "model = models.doc2vec.Doc2Vec(vector_size=40, min_count=2, epochs=200)\n",
    "model.build_vocab(tagged_corpus)\n",
    "model.train(tagged_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['note', 'victori', 'win', 'sec', 'play', '3', 'press', 'top', 'sinc', 'char', 'state', 'footbal', 'anoth', 'one', 'list', 'recent', 'chang', 'arriv', '2020', 'season', 'im', 'final', 'thing', '1', 'field', 'wa', 'raven', 'coach', 'john', 'said', 'friday', 'nfl', 'offic', 'hi', 'face', 'offici', 'dure', 'monday', 'night', 'four', 'took', 'ahead', 'fight', 'ufc', '4', 'talladega', 'known', 'chao', 'ha', 'consist', 'espn', 'bill', 'playoff', 'chanc', 'start', 'alreadi', 'head', 'fan', 'thi', 'posit', 'weekend', 'rival', 'home', 'run', 'deep', 'seven', 'time', 'sam', 'welcom', 'first', 'tri', 'coronaviru', 'pandem', 'last', 'sunday', 'via', 'new', 'england', 'patriot', 'summer', 'go', 'w', '1033', 'end', 'expect', 'quarter', '2', 'take', 'minnesota', 'vike', 'offens', 'line', 'team', 'number', 'year', 'octob', 'thursday', 'ninth', 'bronco', 'quarterback', 'game', 'key', 'player', 'miss', 'yet', 'week', 'matchup', 'lo', 'angel', 'addit', 'wide', 'receiv', 'see', 'led', 'three', 'good', 'news', 'bad', 'back', 'day', 'notr', 'dame', 'univers', 'presid', 'jenkin', 'test', 'covid19', 'detroit', 'red', 'wing', 'steve', 'yzerman', 'oct', 'free', 'made', 'like', 'second', 'half', 'dembel', 'bring', 'san', 'diego', 'padr', 'cardin', 'allen', 'lazard', 'packer', 'lion', 'roster', 'safeti', 'front', 'round', 'tennesse', 'titan', 'adam', 'report', 'predict', 'otherwis', 'friend', 'michael', 'make', 'trip', 'saturday', 'potenti', 'kansa', 'citi', 'chief', 'texa', 'ehling', 'also', 'colleg', 'lamar', 'jackson', 'pick', 'weekli', 'decid', 'scott', 'propos', 'washington', 'turner', 'schedul', 'basebal', 'return', 'announc', 'nba', 'lost', 'injuri', 'saban', 'stay', 'everi', 'grant', 'atkin', 'onc', 'wednesday', 'result'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab.keys()  # this accesses the words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(0, 44), (1, 8), (2, 3), (51, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Assessing Doc2Vec model\n",
    "ranks = []\n",
    "for doc_id in range(len(tagged_corpus)):\n",
    "    inferred_vector = model.infer_vector(tagged_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "# Optimally we want as much documents to be the most similar with themselves (i.e. rank 0)\n",
    "print(collections.OrderedDict(sorted(collections.Counter(ranks).items())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "Above we can the distribution of self-document similarity rank (i.e. ~ 53 documents have itself as the most similar document - rank 0, ~ 2 documents have itself as the second most similar document - rank 0, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (8): «The Yankees wouldnt be in this position, enjoying a lovely four-day weekend before squaring off against their bitter rivals the Rays, without the home run.\n",
      "They went deep seven times against a tough… [+3961 chars]»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS ACCORDING TO DOC2VEC:\n",
      "MOST (8, 0.7446988821029663): «The Yankees wouldnt be in this position, enjoying a lovely four-day weekend before squaring off against their bitter rivals the Rays, without the home run.\n",
      "They went deep seven times against a tough… [+3961 chars]»\n",
      "\n",
      "SECOND-MOST (22, 0.6687438488006592): «The San Diego Padres survived to play another day. Thursday night at Petco Park, the Padres hit five home runs in an epic come-from-behind win over the St. Louis Cardinals in Game 2 of the Wild Card … [+5741 chars]»\n",
      "\n",
      "MEDIAN (31, 0.373639851808548): «SportsPulse: Mackenzie Salmon connected with Texas QB Sam Ehlinger after their crazy comeback win over Texas Tech. Ehlinger also detailed how team is combating COVID and the challenges of college ath… [+5383 chars]»\n",
      "\n",
      "LEAST (30, 0.08854164183139801): «Our friends at OddsChecker sent over an interesting noteregarding the Kansas City Chiefs and New England Patriots matchup on Sunday. The Patriots are seven-point underdogs as they travel to Kansas Ci… [+1033 chars]»\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Document (4): «The next Manning has officially arrived ... and he's VERY real!!!\n",
      "Peyton and Eli Manning's star QB nephew, Arch Manning, kicked off his sophomore season in spectacular fashion Thursday night -- scor… [+950 chars]»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS ACCORDING TO DOC2VEC:\n",
      "MOST (53, 0.8428501486778259): «An unexpectedly abrupt end to the 2020 season on Wednesday led to a sleepless night for Derek Falvey. The Twins' president of baseball operations believed his roster was built for a lengthier playoff… [+5102 chars]»\n",
      "\n",
      "SECOND-MOST (50, 0.8198285102844238): «Viewers watching Wednesday night’s USL match between San Diego Loyal and Phoenix Rising likely ended the first half in a state of confusion. Deep into first half stoppage time, referee Joseph Salinas… [+732 chars]»\n",
      "\n",
      "MEDIAN (21, 0.648966908454895): «Barcelona technical secretary Ramon Planes has played down rumors concerning Ousmane Dembeles future at the club.\n",
      "There is increasing speculation that Manchester United will try to bring in Dembele … [+770 chars]»\n",
      "\n",
      "LEAST (46, 0.12349465489387512): «The Week 4 NFL schedule is stacked with great matchups. Our NFL Nation reporters bring us the keys to every game, a bold prediction for each matchup and final score picks.\n",
      "Additionally, ESPN Stats &… [+30459 chars]»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the train corpus, infer its vector and check similarity with other documents\n",
    "doc_id, sims = check_random_doc_similarity(model, tagged_corpus)\n",
    "compare_documents(doc_id, train_corpus, sims, train_corpus)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------------------------------------------------------\\n\")\n",
    "# Pick a random document from the test corpus, infer its vector and check similarity with other documents\n",
    "doc_id, sims = check_random_doc_similarity(model, tagged_corpus, processed_test_corpus)\n",
    "compare_documents(doc_id, test_corpus, sims, train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (4): «Watch highlights as Jill Roord scores a hat-rick in Arsenal Women's 9-1 thrashing of West Ham United Women in the Women's Super League.\n",
      "MATCH REPORT: West Ham United 1-9 Arsenal Women»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS ACCORDING TO DOC2VEC:\n",
      "MOST (27, 0.9480066895484924): «Mark Zaleski/Associated Press\n",
      "Two more Tennessee Titans players reportedly tested positive for COVID-19 on Friday to bring the total number to seven.\n",
      "ESPN's Adam Schefter reported the update and no… [+1848 chars]»\n",
      "\n",
      "SECOND-MOST (15, 0.9265896081924438): «The Buccaneers had some key players missing yet again on Thursday as they head into their week four matchup with the Los Angeles Chargers. In addition to wide receiver Chris Godwin being out, the Buc… [+722 chars]»\n",
      "\n",
      "MEDIAN (47, 0.7659059762954712): «Patrick Mahomes credits Peloton for staying in Super Bowl-winning shape.\n",
      "In a recent interview with GQ, the Kansas City Chiefs quarterback spoke about his workout regimen during the COVID-19 pandemi… [+3012 chars]»\n",
      "\n",
      "LEAST (26, 0.1728525608778): «Spraying disinfectant to clean seats, handrails, and glass partitions»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get new news articles\n",
    "new_articles = newsapi.get_everything(language='en',\n",
    "                                      domains='bbc.co.uk',\n",
    "                                      from_param=datetime.today() - timedelta(30),\n",
    "                                      to=datetime.today() - timedelta(20),\n",
    "                                      page_size=10)\n",
    "\n",
    "new_corpus = list(set([c['content'] for c in new_articles['articles'] if c['content']]))\n",
    "\n",
    "# Apply preprocessing\n",
    "new_processed_corpus = prep.transform(new_corpus)\n",
    "\n",
    "# Similarity query\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "unkwnown_doc = new_processed_corpus[doc_id]\n",
    "sims = similarity_query(model, unkwnown_doc)\n",
    "compare_documents(doc_id, new_corpus, sims, train_corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
